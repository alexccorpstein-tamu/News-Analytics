{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dac4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topic_number = 20\n",
    "\n",
    "number_of_docs = 100000\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/mnt/nfs-scratch/ECEN_403-404/team_12/James_env/abcnews-date-text.csv\",\n",
    "                header = 0,\n",
    "                nrows = number_of_docs)\n",
    "\n",
    "#print(df.head())\n",
    "\n",
    "date = df['publish_date'].tolist()\n",
    "headline = df['headline_text'].tolist()\n",
    "\n",
    "#print(headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8db98488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stoplist = set('for a of the and to in be'.split())\n",
    "\n",
    "texts = [ [word for word in document.lower().split() if word not in stoplist] for document in headline]\n",
    "\n",
    "#print(text)\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [ [token for token in text if frequency[token] > 1] for text in texts]\n",
    "\n",
    "\n",
    "dictionary  = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#print(corpus)\n",
    "#print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfeded58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=100000, num_nnz=559593)\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d11ed860",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "\n",
    "##for doc in corpus_tfidf:\n",
    "    #print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64f92f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.ldamodel.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=topic_number)\n",
    "corpus_lda = lda_model[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6776953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model.print_topics(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07a58104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for doc, as_text in zip(corpus_lda, headline):\n",
    "    #print(doc, as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5326949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -13.669946199465166\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity: \", lda_model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c0e45ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -13.02748518382138\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = models.coherencemodel.CoherenceModel(model = lda_model,texts = texts, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(\"\\nCoherence Score: \", coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc33c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "310e38aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 0, 0.012500793], [7, 0, 0.37271065]]\n",
      "[[5, 1, 0.2606819], [7, 1, 0.2472593]]\n",
      "[[0, 2, 0.5784828], [1, 2, 0.72142965], [5, 2, 0.012500793], [6, 2, 0.21499288], [7, 2, 0.010001246]]\n",
      "[[3, 3, 0.22633325], [4, 3, 0.15863232], [5, 3, 0.012500793], [7, 3, 0.010001246], [10, 3, 0.21218155]]\n",
      "[[5, 4, 0.012500793], [7, 4, 0.010001246]]\n",
      "[[4, 5, 0.4488415], [5, 5, 0.012500793], [7, 5, 0.010001246]]\n",
      "[[2, 6, 0.17499225], [5, 6, 0.012500793], [7, 6, 0.010001246]]\n",
      "[[0, 7, 0.2929126], [5, 7, 0.012500793], [7, 7, 0.010001246]]\n",
      "[[5, 8, 0.012500793], [7, 8, 0.010001246], [9, 8, 0.31898034]]\n",
      "[[1, 9, 0.14998913], [2, 9, 0.29125455], [5, 9, 0.012500793], [7, 9, 0.010001246], [9, 9, 0.55241567]]\n",
      "[[3, 10, 0.6611643], [4, 10, 0.2710697], [5, 10, 0.012500793], [7, 10, 0.010001246]]\n",
      "[[5, 11, 0.012500793], [7, 11, 0.010001246]]\n",
      "[[5, 12, 0.012500793], [7, 12, 0.010001246], [8, 12, 0.5518095]]\n",
      "[[2, 13, 0.1749822], [5, 13, 0.012500793], [7, 13, 0.2100089], [10, 13, 0.15883815]]\n",
      "[[5, 14, 0.012500793], [7, 14, 0.010001246]]\n",
      "[[5, 15, 0.012500793], [7, 15, 0.010001246], [10, 15, 0.16827396]]\n",
      "[[2, 16, 0.2254219], [5, 16, 0.012500793], [6, 16, 0.22272214], [7, 16, 0.010001246]]\n",
      "[[5, 17, 0.012500793], [6, 17, 0.17572984], [7, 17, 0.010001246]]\n",
      "[[5, 18, 0.012500793], [6, 18, 0.2531744], [7, 18, 0.010001246]]\n",
      "[[5, 19, 0.5143038], [7, 19, 0.010001246], [8, 19, 0.3356838], [10, 19, 0.34635773]]\n"
     ]
    }
   ],
   "source": [
    "topic_buckets = [[]]\n",
    "for j in range(1,topic_number):\n",
    "    topic_buckets.append([])\n",
    "    \n",
    "#print(topic_buckets)\n",
    "for i in range(0,11):\n",
    "    document_topic = list(models.ldamodel.LdaModel.get_document_topics(lda_model, \n",
    "                                                                       bow=corpus[i], \n",
    "                                                                       minimum_probability=None, \n",
    "                                                                       minimum_phi_value=None, \n",
    "                                                                       per_word_topics=False))\n",
    "    \n",
    "    \n",
    "    for topic in document_topic:\n",
    "        list_topic = list(topic)\n",
    "        list_topic.insert(0,i)\n",
    "        #rint(list_topic)\n",
    "        topic_buckets[list_topic[1]].append(list_topic)\n",
    "    #print(document_topic)\n",
    "    \n",
    "for i in topic_buckets:\n",
    "    print(i)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c2ea2",
   "metadata": {},
   "source": [
    "**This Next Cell is Used to Save the Model Only Run it if you want to erase the previous model and save the new one**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4593bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "##tempfile.NamedTemporaryFile(mode='w+b', \n",
    "    #buffering=None, encoding=None, newline=None, suffix=None, prefix=None, dir=None, delete=Tru\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='model-', suffix='.lsi', delete=False, dir = '/mnt/nfs-scratch/ECEN_403-404/team_12/James_env') as tmp:\n",
    "    lda_model.save(tmp.name)  # same for tfidf, lda, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a4c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
