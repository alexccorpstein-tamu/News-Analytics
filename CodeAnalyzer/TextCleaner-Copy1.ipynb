{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee8ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/jnieberding/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import required packages\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('vader_lexicon')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8970148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index                                            article          topic\n",
      "0         0  musicians tackle red tape musicians groups tac...  entertainment\n",
      "1         1  u2 desire number u2 won prestigious grammy awa...  entertainment\n",
      "2         2  rocker doherty stage fight rock singer pete do...  entertainment\n",
      "3         3  snicket tops box office chart film adaptation ...  entertainment\n",
      "4         4  ocean raids box office ocean crime caper seque...  entertainment\n",
      "...     ...                                                ...            ...\n",
      "2220   2220  norway upholds napster ruling norwegian studen...           tech\n",
      "2221   2221  warning windows word files writing microsoft w...           tech\n",
      "2222   2222  fast lifts record books high speed lifts world...           tech\n",
      "2223   2223  nintendo adds media playing ds nintendo releas...           tech\n",
      "2224   2224  fast moving phone viruses appear security firm...           tech\n",
      "\n",
      "[2225 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#CSV Code for reading in data from dataset.csv\n",
    "#date, publisher, headline, article data for csv\n",
    "#os.getcwd()\n",
    "\n",
    "dataframe = pd.read_csv('/home/jnieberding/LocalCapstone/env/tfidf_dataset.csv')\n",
    "dataframe = dataframe.dropna()\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc290e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a401c2d0c41b09d9838434f110b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#results dicitonary is a list for the NLTK scores\n",
    "results = {}\n",
    "\n",
    "#blobRes dictionary is a list for blobText scores\n",
    "blobRes = {}\n",
    "\n",
    "#texts dictionary is a list for the conent of the articles to be cleaned\n",
    "texts = {}\n",
    "\n",
    "#heads is a dictionary for the content of the headings to be cleaned\n",
    "#heads = {}\n",
    "sent = SentimentIntensityAnalyzer()\n",
    "\n",
    "#loop to extract article content/heading and clean for each article \n",
    "for i, row in tqdm(dataframe.iterrows(), total = len(dataframe)):\n",
    "    #assign row variables\n",
    "    text = row['article']\n",
    "    Id = row['index']\n",
    "    #heading = row['headline']\n",
    "    \n",
    "    #normalize text (lowercase)\n",
    "    text = text.lower()\n",
    "    \n",
    "    #split text for cleaning\n",
    "    split_text = text.split()\n",
    "    \n",
    "    #remove all ampersans(&) and replace with \"and\"\n",
    "    andText = [word.replace(\"a&m\",\"aandm\") for word in split_text]\n",
    "\n",
    "    #cleans text for all things not alphabetical\n",
    "    alphatext = [word for word in andText if word.isalpha()]\n",
    "    \n",
    "    #get stopwords from NLTK stopwords package\n",
    "    NLTKstopwords = set(stopwords.words('english'))\n",
    "    \n",
    "    #clean text by saying that if the word is not in nltk stopwords list,\n",
    "    #then add that word to the cleantext list\n",
    "    cleantext = [word for word in alphatext if word not in NLTKstopwords]\n",
    "    \n",
    "    #lemmatize text\n",
    "    wl = WordNetLemmatizer()\n",
    "    lemText = [wl.lemmatize(y) for y in cleantext]\n",
    "    \n",
    "    #this takes the cleantext list and makes it a string\n",
    "    blobtext = ' '.join(lemText)\n",
    "    \n",
    "    #for each article, take the polarity scores\n",
    "    results[Id] = sent.polarity_scores(blobtext)\n",
    "    texts[Id] = blobtext\n",
    "    \n",
    "    #now clean the headings for James\n",
    "    #heading = heading.lower()\n",
    "    \n",
    "    #split into list of words\n",
    "    #split_heading = heading.split()\n",
    "    \n",
    "    #clean headings for all things not alphabetical\n",
    "    #alphahead = [word for word in split_heading if word.isalpha()]\n",
    "    \n",
    "    #remove stopwords from the alphabetical words\n",
    "    #cleanhead = [word for word in alphahead if word not in NLTKstopwords]\n",
    "    \n",
    "    #join the list cleanhead into a single string to be analyed\n",
    "    #blobhead = ' '.join(cleanhead)\n",
    "    \n",
    "    #put into a list of cleaned strings for each header\n",
    "    #heads[Id] = blobhead\n",
    "    \n",
    "    #put into a list of cleaned content for each article\n",
    "    \n",
    "    #obtain list of each TextBlob sentiment/subjectivity score from the blobtext variable\n",
    "    blobRes[Id] = (TextBlob(blobtext).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e0cb5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fast', 'moving', 'phone', 'virus', 'appear', 'security', 'firm', 'warning', 'mobile', 'phone', 'virus', 'spread', 'faster', 'similar', 'bug', 'new', 'strain', 'cabir', 'mobile', 'phone', 'virus', 'short', 'range', 'technology', 'leap', 'vulnerable', 'phone', 'soon', 'range', 'cabir', 'virus', 'affect', 'handset', 'running', 'symbian', 'series', 'phone', 'operating', 'warning', 'far', 'report', 'phone', 'infected', 'new', 'variant', 'cabir', 'original', 'cabir', 'worm', 'light', 'mid', 'june', 'sent', 'anti', 'virus', 'firm', 'proof', 'concept', 'program', 'mistake', 'original', 'cabir', 'written', 'meant', 'escaped', 'laboratory', 'bug', 'infect', 'phone', 'new', 'cabir', 'strain', 'mistake', 'corrected', 'spread', 'short', 'range', 'bluetooth', 'technology', 'vulnerable', 'phone', 'range', 'bluetooth', 'effective', 'range', 'ten', 'metre', 'risk', 'infected', 'cabir', 'low', 'user', 'malicious', 'program', 'permission', 'download', 'handset', 'manually', 'install', 'user', 'protect', 'altering', 'setting', 'symbian', 'phone', 'conceals', 'handset', 'bluetooth', 'device', 'finnish', 'security', 'firm', 'f', 'secure', 'issued', 'warning', 'new', 'strain', 'cabir', 'virus', 'damage', 'phone', 'block', 'normal', 'bluetooth', 'activity', 'drain', 'phone', 'battery', 'anti', 'virus', 'firm', 'sophos', 'source', 'code', 'cabir', 'posted', 'brazilian', 'programmer', 'lead', 'variant', 'program', 'created', 'far', 'seven', 'version', 'cabir', 'exist', 'inside', 'malicious', 'skull', 'program', 'late', 'november', 'symbian', 'series', 'software', 'licenced', 'nokia', 'lg', 'electronics', 'lenovo', 'panasonic', 'samsung', 'sendo', 'siemens']\n"
     ]
    }
   ],
   "source": [
    "print(lemText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5094302d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68632492fd39492eb3eb3d04afb7d640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#obtain datadrame from results list using pandas\n",
    "NLTK = pd.DataFrame(results).T\n",
    "\n",
    "#reset the dataframe index and change column name to Id\n",
    "NLTK = NLTK.reset_index(drop = True)\n",
    "\n",
    "#combine the results data witht the original csv dataframe\n",
    "vaders = pd.concat([dataframe, NLTK], axis = 1, join = 'outer')\n",
    "\n",
    "#create dataframe using list of TextBlob scores\n",
    "BlobFrame = pd.DataFrame(blobRes).T\n",
    "\n",
    "#re-lable columns for better readability\n",
    "BlobFrame.columns = ['Sentiment', 'Subjectivity']\n",
    "\n",
    "#reset blobframe index so that when concated, they line up\n",
    "BlobFrame = BlobFrame.reset_index(drop = True)\n",
    "\n",
    "#combine the updated csv (from the last line of code) to the textblob scores dataframe\n",
    "vaderBlob = pd.concat([vaders, BlobFrame], axis = 1, join = 'outer')\n",
    "\n",
    "#initialize k\n",
    "k = 0\n",
    "\n",
    "#replace the heading with cleaned heading using a loop\n",
    "for i, row in tqdm(vaders.iterrows(), total = len(vaders)):\n",
    "    #heading = row['headline']\n",
    "    text = row['article']\n",
    "    \n",
    "    #set the headings to be replaced to the list of head at position k\n",
    "    #headreplace = heads[k]\n",
    "    textreplace = texts[k]\n",
    "    \n",
    "    #replace the headings and update the vaderBlob dataframe by setting it equal to the new replaced dataframe\n",
    "    #vaderBlob = vaderBlob.replace(heading, headreplace)\n",
    "    vaderBlob = vaderBlob.replace(text, textreplace)\n",
    "    \n",
    "    #move index forward 1\n",
    "    k = k + 1\n",
    "    \n",
    "#save this updated csv to a new file \n",
    "vaderBlob.to_csv(\"/home/jnieberding/LocalCapstone/env/training_tfidf1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3b61d",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cb3832e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['despite', 'fall', 'year', 'roman', 'empire', 'resurges', 'popular', 'conscience', 'every', 'gladiator', 'one', 'financially', 'successful', 'film', 'five', 'academy', 'inspired', 'spartacus', 'went', 'inspire', 'several', 'piece', 'television', 'show', 'roman', 'empire', 'pleb', 'britannia', 'many', 'latest', 'homage', 'roman', 'empire', 'arrived', 'meme', 'started', 'social', 'medium', 'phenomenon', 'wherein', 'spouse', 'would', 'ask', 'partner', 'often', 'think', 'roman', 'covered', 'rolling', 'stone', 'common', 'surprised', 'people', 'think', 'roman', 'empire', 'quite', 'asked', 'texas', 'university', 'history', 'professor', 'late', 'middle', 'age', 'expert', 'daniel', 'schwartz', 'thought', 'people', 'think', 'much', 'roman']\n"
     ]
    }
   ],
   "source": [
    "###############################################PRACTICE/TEST#####################################################\n",
    "#begin with text cleaning\n",
    "#can remove HTML depending on text source\n",
    "#sample text \n",
    "wl = WordNetLemmatizer()\n",
    "text = \"Despite its fall more than 1500 years ago, the Roman Empire resurges in the popular conscience every so often. For example, Gladiator (2000), one of the most financially successful films of the 2000s that won five Academy Awards, was inspired by Ben-Hur (1959) and Spartacus (1960) and went on to inspire several pieces of media, such as television shows Roman Empire (2016-2019), Plebs (2013-2019), Britannia (2017–2021) and many more. The latest homage to the Roman Empire has arrived in meme form. What started as a social media phenomenon wherein spouses would ask their partners “How often do you think about the Roman Empire?” has now been covered by CNN, Wired, Forbes, Rolling Stone and others. The common denominator, which has surprised many, has been that people think about the Roman Empire quite a lot, actually. As such, we asked Texas A&M University history professor and late Antiquity/early Middle Ages expert Dr. Daniel Schwartz for his thoughts on why people think so much about the Roman Empire.\"\n",
    "#normalize text (lowercase)\n",
    "text = text.lower()\n",
    "#split text for cleaning\n",
    "split_text = text.split()\n",
    "#cleans text for all things not alphabetical\n",
    "alphatext = [word for word in split_text if word.isalpha()]\n",
    "#get stopwords from NLTK stopwords package\n",
    "NLTKstopwords = set(stopwords.words('english'))\n",
    "cleantext = [word for word in alphatext if word not in NLTKstopwords]\n",
    "lemText = [wl.lemmatize(y) for y in cleantext]\n",
    "print(lemText)\n",
    "#print(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a903c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing tokenization\n",
    "tokenized_text = nltk.pos_tag(split_text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87d4d8ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "despite fall years roman empire resurges popular conscience every gladiator one financially successful films five academy inspired spartacus went inspire several pieces television shows roman empire plebs britannia many latest homage roman empire arrived meme started social media phenomenon wherein spouses would ask partners often think roman covered rolling stone common surprised people think roman empire quite asked texas university history professor late middle ages expert daniel schwartz thoughts people think much roman\n",
      "Sentiment(polarity=0.18939393939393942, subjectivity=0.5015151515151515)\n"
     ]
    }
   ],
   "source": [
    "#with textblob, we can analyze this text for subjectivty/sentiment, but the technical merit might not be there.\n",
    "blobtext = ' '.join(cleantext)\n",
    "print(blobtext)\n",
    "SS = TextBlob(blobtext)\n",
    "final_score = SS.sentiment\n",
    "print(final_score)\n",
    "ment us\n",
    "#entity analysis\n",
    "#topic formation\n",
    "#tone  analysis\n",
    "#python visuals\n",
    "#google co-lab ML environment uses google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282fb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
